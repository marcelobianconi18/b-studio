# ü§ñ Configura√ß√£o de Modelos Qwen no Antigravity

## ‚úÖ Modelos Instalados no SSD Externo

| Modelo | Tamanho | Uso Ideal |
|--------|---------|-----------|
| **qwen2.5:7b** | 4.7 GB | ‚úÖ Conversas, explica√ß√µes, c√≥digo b√°sico |
| **qwen2.5-coder:7b** | 4.7 GB | ‚úÖ C√≥digo, debug, refatora√ß√£o |
| **qwen2.5-coder:14b** | 9.0 GB | ‚úÖ C√≥digo complexo, an√°lise profunda |
| **llama3:latest** | 4.7 GB | ‚úÖ Uso geral |

---

## ‚öôÔ∏è Como Usar no Antigravity

### **Op√ß√£o 1: Via Settings (Recomendado)**

1. **Abra o Antigravity**
2. **Cmd+,** (Configura√ß√µes)
3. **Procure por:** `AI Model` ou `Ollama`
4. **Mude o modelo:**
   ```
   qwen2.5:7b         ‚Üí Para conversas
   qwen2.5-coder:7b   ‚Üí Para c√≥digo
   qwen2.5-coder:14b  ‚Üí Para c√≥digo complexo
   ```

### **Op√ß√£o 2: Via Comando R√°pido**

1. **Cmd+Shift+P**
2. **Digite:** `Change AI Model`
3. **Selecione:** O modelo desejado

---

## üîÑ Trocar de Modelo no Meio da Conversa

**Sim! √â poss√≠vel!**

### **No Antigravity:**

1. **Abra a paleta de comandos:** `Cmd+Shift+P`
2. **Digite:** `Change Model` ou `Select AI Model`
3. **Escolha:** O modelo desejado
4. **Continue a conversa** com o novo modelo

### **Modelos Recomendados por Tarefa:**

| Tarefa | Modelo Ideal |
|--------|--------------|
| **Conversar, explicar conceitos** | `qwen2.5:7b` ‚úÖ |
| **Escrever c√≥digo** | `qwen2.5-coder:7b` ‚úÖ |
| **Debug complexo** | `qwen2.5-coder:14b` ‚úÖ |
| **An√°lise de arquitetura** | `qwen2.5-coder:14b` ‚úÖ |
| **Tarefas r√°pidas** | `qwen2.5:7b` ou `llama3:latest` |

---

## üìç Localiza√ß√£o dos Modelos

```
/Volumes/SSD Externo/ai-models/ollama/models/
```

---

## üöÄ Comandos √öteis

### **Ver modelos instalados:**
```bash
OLLAMA_MODELS="/Volumes/SSD Externo/ai-models/ollama/models" ollama list
```

### **Baixar mais modelos:**
```bash
# Qwen 2.5 14B (mais potente)
OLLAMA_MODELS="/Volumes/SSD Externo/ai-models/ollama/models" ollama pull qwen2.5:14b

# Qwen 2.5 32B (m√°ximo)
OLLAMA_MODELS="/Volumes/SSD Externo/ai-models/ollama/models" ollama pull qwen2.5:32b
```

### **Testar modelo:**
```bash
OLLAMA_MODELS="/Volumes/SSD Externo/ai-models/ollama/models" ollama run qwen2.5:7b "Ol√°, como vai?"
```

---

## üí° Dica de Fluxo de Trabalho

### **No Antigravity:**

1. **Crie m√∫ltiplas janelas/abas** do Antigravity
2. **Nomeie cada uma:**
   - `Qwen Conversa` ‚Üí `qwen2.5:7b`
   - `Qwen Code` ‚Üí `qwen2.5-coder:7b`
   - `Qwen Max` ‚Üí `qwen2.5-coder:14b`
3. **Alterne entre abas** conforme a tarefa

---

## ‚úÖ Status

- ‚úÖ **Ollama configurado** para usar SSD Externo
- ‚úÖ **Qwen 2.5 7B instalado** (conversas)
- ‚úÖ **Qwen 2.5 Coder 14B instalado** (c√≥digo)
- ‚úÖ **Qwen 2.5 Coder 7B instalado** (c√≥digo leve)
- ‚úÖ **Llama3 instalado** (geral)

---

**Pronto! Agora √© s√≥ usar!** üöÄ
